{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dreem_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wTa_9UrPxZx",
        "outputId": "b2d1b128-9fde-40d3-bf06-5aefcae80fe4"
      },
      "source": [
        "!git clone https://github.com/clementgr/detect-sleep-apnea.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'detect-sleep-apnea'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 9 (delta 0), reused 6 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEdCl322P0Ds"
      },
      "source": [
        "import os\n",
        "os.chdir('detect-sleep-apnea')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwg-OGYPQHRe",
        "outputId": "d7e3ef92-9e9c-4427-cb49-78b851dde58c"
      },
      "source": [
        "!sh scripts/data_download.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wK0S9dmFqwNZV_Uq3ToD9zsWzltcsi8x\n",
            "To: /content/detect-sleep-apnea/data.zip\n",
            "3.94GB [01:08, 57.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duko4vWOQK2p"
      },
      "source": [
        "%%capture\n",
        "!unzip data.zip\n",
        "!rm data.zip\n",
        "!rm -r __MACOSX\n",
        "!rm -r /content/sample_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38paR298Tcvn"
      },
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAcPqv36CeFu"
      },
      "source": [
        "path_to_train_data = 'data/X_train.h5'\n",
        "path_to_label_data = 'data/y_train_tX9Br0C.csv'\n",
        "x_train = h5py.File(path_to_train_data, mode='r')\n",
        "y_train = pd.read_csv(path_to_label_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsD6Ay7vDsN9",
        "outputId": "ef3db873-f9f3-4e2e-fa75-dacb211045f1"
      },
      "source": [
        "x_train['data'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4400, 72002)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "eXcE4HnKMx1F",
        "outputId": "5268081b-5517-4363-8f25-53f2c951a38b"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>y_0</th>\n",
              "      <th>y_1</th>\n",
              "      <th>y_2</th>\n",
              "      <th>y_3</th>\n",
              "      <th>y_4</th>\n",
              "      <th>y_5</th>\n",
              "      <th>y_6</th>\n",
              "      <th>y_7</th>\n",
              "      <th>y_8</th>\n",
              "      <th>y_9</th>\n",
              "      <th>y_10</th>\n",
              "      <th>y_11</th>\n",
              "      <th>y_12</th>\n",
              "      <th>y_13</th>\n",
              "      <th>y_14</th>\n",
              "      <th>y_15</th>\n",
              "      <th>y_16</th>\n",
              "      <th>y_17</th>\n",
              "      <th>y_18</th>\n",
              "      <th>y_19</th>\n",
              "      <th>y_20</th>\n",
              "      <th>y_21</th>\n",
              "      <th>y_22</th>\n",
              "      <th>y_23</th>\n",
              "      <th>y_24</th>\n",
              "      <th>y_25</th>\n",
              "      <th>y_26</th>\n",
              "      <th>y_27</th>\n",
              "      <th>y_28</th>\n",
              "      <th>y_29</th>\n",
              "      <th>y_30</th>\n",
              "      <th>y_31</th>\n",
              "      <th>y_32</th>\n",
              "      <th>y_33</th>\n",
              "      <th>y_34</th>\n",
              "      <th>y_35</th>\n",
              "      <th>y_36</th>\n",
              "      <th>y_37</th>\n",
              "      <th>y_38</th>\n",
              "      <th>...</th>\n",
              "      <th>y_50</th>\n",
              "      <th>y_51</th>\n",
              "      <th>y_52</th>\n",
              "      <th>y_53</th>\n",
              "      <th>y_54</th>\n",
              "      <th>y_55</th>\n",
              "      <th>y_56</th>\n",
              "      <th>y_57</th>\n",
              "      <th>y_58</th>\n",
              "      <th>y_59</th>\n",
              "      <th>y_60</th>\n",
              "      <th>y_61</th>\n",
              "      <th>y_62</th>\n",
              "      <th>y_63</th>\n",
              "      <th>y_64</th>\n",
              "      <th>y_65</th>\n",
              "      <th>y_66</th>\n",
              "      <th>y_67</th>\n",
              "      <th>y_68</th>\n",
              "      <th>y_69</th>\n",
              "      <th>y_70</th>\n",
              "      <th>y_71</th>\n",
              "      <th>y_72</th>\n",
              "      <th>y_73</th>\n",
              "      <th>y_74</th>\n",
              "      <th>y_75</th>\n",
              "      <th>y_76</th>\n",
              "      <th>y_77</th>\n",
              "      <th>y_78</th>\n",
              "      <th>y_79</th>\n",
              "      <th>y_80</th>\n",
              "      <th>y_81</th>\n",
              "      <th>y_82</th>\n",
              "      <th>y_83</th>\n",
              "      <th>y_84</th>\n",
              "      <th>y_85</th>\n",
              "      <th>y_86</th>\n",
              "      <th>y_87</th>\n",
              "      <th>y_88</th>\n",
              "      <th>y_89</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 91 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  y_0  y_1  y_2  y_3  y_4  y_5  ...  y_83  y_84  y_85  y_86  y_87  y_88  y_89\n",
              "0   0    0    0    0    0    0    0  ...     0     0     0     0     0     0     0\n",
              "1   1    0    0    0    0    0    0  ...     0     0     0     0     0     0     0\n",
              "2   2    0    0    0    0    0    0  ...     0     0     0     0     0     0     0\n",
              "3   3    0    0    0    0    0    0  ...     0     0     0     0     0     0     0\n",
              "4   4    0    0    0    0    0    0  ...     0     0     0     0     0     0     0\n",
              "\n",
              "[5 rows x 91 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntj-HtmND07C",
        "outputId": "832d3735-ce6f-47f7-ed22-fbbeceedcc6a"
      },
      "source": [
        "dset = x_train['data']\n",
        "len(dset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7lxgwbGD9PU"
      },
      "source": [
        "import torch\n",
        "\n",
        "class SleepApneaDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, data_path, csv_path, N_signals=8, signal_freq=100):\n",
        "\n",
        "    self.dset = h5py.File(data_path, mode='r')['data']\n",
        "    self.targets = pd.read_csv(csv_path)\n",
        "    self.N = N_signals\n",
        "    self.freq = signal_freq\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.dset)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    \n",
        "    sample_index = self.dset[idx, 0]\n",
        "    subject_index = self.dset[idx, 1]\n",
        "    x = self.dset[idx, 2:].reshape(-1, self.N)\n",
        "    y = self.targets[self.targets['ID'] == sample_index].values[0][1:]\n",
        "\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wRcBkohNKx-"
      },
      "source": [
        "train_dset = SleepApneaDataset('data/X_train.h5', 'data/y_train_tX9Br0C.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuwmRFRSQ38a"
      },
      "source": [
        "import torch\n",
        "\n",
        "class OneChannelDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, data_path, csv_path, signal_id=0, signal_freq=100):\n",
        "\n",
        "    self.dset = h5py.File(data_path, mode='r')['data']\n",
        "    self.targets = pd.read_csv(csv_path)\n",
        "    self.signal_id = signal_id\n",
        "    self.freq = signal_freq\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.dset)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    \n",
        "    sample_index = self.dset[idx, 0]\n",
        "    subject_index = self.dset[idx, 1]\n",
        "    x = self.dset[idx, 2+9000*self.signal_id:2+9000*(self.signal_id+1)]\n",
        "    x = x.reshape(-1, self.freq)\n",
        "    y = self.targets[self.targets['ID'] == sample_index].values[0][1:]\n",
        "\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1SxeTm3Tesx"
      },
      "source": [
        "train_dset = OneChannelDataset('data/X_train.h5', 'data/y_train_tX9Br0C.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn7pL_0oNcS_",
        "outputId": "2e97cd25-65f5-45e3-84cf-159816d16196"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dset, batch_size=16, shuffle=False)\n",
        "next(iter(train_loader))[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 90, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asXVV0HUNsGd"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, seq_length, input_size, hidden_dim, output_dim, n_layers, \n",
        "              bidirectional, dropout_p):\n",
        "    \n",
        "    super().__init__()\n",
        "    \n",
        "    self.bidirectional = bidirectional\n",
        "    \n",
        "    self.rnn = nn.LSTM(input_size=input_size, \n",
        "                      hidden_size=256, \n",
        "                      num_layers=n_layers, \n",
        "                      bidirectional=bidirectional, \n",
        "                      dropout=dropout_p)\n",
        "    \n",
        "    fc_input_dim = 2*hidden_dim if self.bidirectional else hidden_dim\n",
        "    self.fc = nn.Linear(fc_input_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    \n",
        "    output, (hidden, cell) = self.rnn(x)\n",
        "\n",
        "    if self.bidirectional:\n",
        "      hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
        "    else:\n",
        "      hidden = self.dropout(hidden[-1,:,:])\n",
        "            \n",
        "    # hidden = [batch size, hid dim * num directions]\n",
        "        \n",
        "    return torch.sigmoid(self.fc(hidden))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lXpzevtQXS5"
      },
      "source": [
        "seq_length = 90\n",
        "input_size = 100\n",
        "hidden_dim = 256\n",
        "output_dim = 90\n",
        "n_layers = 2\n",
        "bidir = True\n",
        "dropout_p = 0.1\n",
        "\n",
        "model = LSTM(seq_length, input_size, hidden_dim, output_dim, n_layers, bidir, dropout_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJqnI0QlQ7oG",
        "outputId": "0e41bb11-e99d-48f6-86d0-d58c443c02b4"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPsJK80JQtjb"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "model = model.to(device)\n",
        "criterion = nn.BCELoss()\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vScRLoT7VcDN",
        "outputId": "45053e4a-492d-4a08-eff9-4f30f3902110"
      },
      "source": [
        "tmp_criterion = nn.BCELoss()\n",
        "a = np.zeros(90)\n",
        "b = y_train.iloc[1].values[1:].astype('float')\n",
        "tmp_criterion(torch.from_numpy(b), torch.from_numpy(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0., dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmI8NYl9ZEIq",
        "outputId": "46e03c70-2545-4873-e355-be5f8014ceb8"
      },
      "source": [
        "y_train.iloc[1].values[1:].astype('float')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpPys-0rROn8"
      },
      "source": [
        "from metric_dreem import dreem_sleep_apnea_custom_metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJZPeyprQ4wR"
      },
      "source": [
        "def train(model, train_loader, optimizer, criterion):\n",
        "    \n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.train()\n",
        "  \n",
        "  for signal, target in train_loader:\n",
        "      \n",
        "    optimizer.zero_grad()\n",
        "    signal = signal.type(torch.FloatTensor)\n",
        "    signal, target = signal.to(device), target.to(device)\n",
        "    # print(f'signal.dtype: {signal.dtype}')\n",
        "    signal = signal.permute(1,0,2)\n",
        "    # print(f'signal.shape: {signal.shape}')\n",
        "    preds = model(signal).squeeze(1)\n",
        "    # print(f'preds.shape: {preds.shape}')\n",
        "    # print(f'preds.dtype: {preds.dtype}')\n",
        "    # print(f'target.shape: {target.shape}')\n",
        "    # print(f'target.dtype: {target.dtype}')\n",
        "    preds = preds.type(torch.FloatTensor).cpu()\n",
        "    target = target.type(torch.FloatTensor).cpu()\n",
        "    # print((preds.detach()>0.5).float())\n",
        "    # print(target)\n",
        "    # print()\n",
        "    loss = criterion(preds, target)\n",
        "    # acc = dreem_sleep_apnea_custom_metric((preds.detach()>0.5).float(), target.detach())\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    epoch_loss += loss.item()\n",
        "    # epoch_acc += acc\n",
        "\n",
        "  # return epoch_loss / len(train_loader), epoch_acc / len(train_loader)\n",
        "  return epoch_loss / len(train_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMRpzAjnRni_"
      },
      "source": [
        "def evaluate(model, val_loader, criterion):\n",
        "    \n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.eval()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "  \n",
        "    for signal, target in val_loader:\n",
        "\n",
        "      signal, target = signal.to(device), target.to(device)\n",
        "      preds = model(signal).squeeze(1)\n",
        "      loss = criterion(preds, target)\n",
        "      # acc = dreem_sleep_apnea_custom_metric(preds.cpu(), target.cpu())\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      # epoch_acc += acc\n",
        "    \n",
        "  # return epoch_loss / len(val_loader), epoch_acc / len(val_loader)\n",
        "  return epoch_loss / len(val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XldQJP7YR-np"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e348UZWCR0-i"
      },
      "source": [
        "n_epochs = 20\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  start_time = time.time()\n",
        "  \n",
        "  # train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
        "  # valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
        "\n",
        "  train_loss = train(model, train_loader, optimizer, criterion)\n",
        "  # valid_loss = evaluate(model, val_loader, criterion)\n",
        "\n",
        "  end_time = time.time()\n",
        "\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "  \n",
        "  # if valid_loss < best_valid_loss:\n",
        "  #   best_valid_loss = valid_loss\n",
        "  #   torch.save(model.state_dict(), 'best_model.pt')\n",
        "\n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "  # print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
        "  # print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "  # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd2Yv6caSCcl"
      },
      "source": [
        "a = pd.read_csv('/content/y_random.csv')\n",
        "a.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gezeyUv3aMDN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}